{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH_j9_nQbIEN"
      },
      "source": [
        "Proyecto 1 BI\n",
        "Tema: Datos Peliculas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JNTJIJBnEfX"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAs8LeOUnEMP"
      },
      "source": [
        "# Set Up Inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buZb9lcVnatg"
      },
      "source": [
        "# Cargar Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "vN0EJL04m73_",
        "outputId": "251653ac-3ef6-4909-e1fc-6d497bb43e45"
      },
      "outputs": [],
      "source": [
        "tweets_df = pd.read_csv('/Users/pipe/Desktop/GitHub/BI/Etapa 1/Archivos/MovieReviews.csv', sep = ',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reAJpchGn7Mo"
      },
      "source": [
        "# Filtrando Tuits No Etiquetados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4yrCzP-Im8Cd"
      },
      "outputs": [],
      "source": [
        "tweets_labeled_df = tweets_df.loc[tweets_df['sentimiento'].notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_df['sentimiento'] = tweets_df['sentimiento'].map({'positivo': 1, 'negativo': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HzP7mryvn-z5"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets_df['review_es'], tweets_df['sentimiento'], test_size = 0.2, stratify = tweets_df['sentimiento'], random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRPk43VBe4Qa"
      },
      "source": [
        "# Pipeline Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HA5rO7_tiwKR"
      },
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q0nlbVJoe59Q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/pipe/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Descargando las stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "    ('vectorizer', CountVectorizer(tokenizer=tokenizer.tokenizer, stop_words=stop_words, lowercase=True)),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=200, min_samples_split=5, max_depth=5, criterion='entropy'))\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pipe = pipeline.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['modelo.joblib']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dump(pipe, 'modelo.joblib')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora probemos que el joblib quedo bien"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.82\n",
            "Precision: 0.80\n",
            "Recall: 0.87\n",
            "F1-Score: 0.83\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# load the trained joblib model\n",
        "model = joblib.load('assets/modelo.joblib')\n",
        "\n",
        "# make predictions on the test dataset\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluate the performance of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print('Accuracy: {:.2f}'.format(accuracy))\n",
        "print('Precision: {:.2f}'.format(precision))\n",
        "print('Recall: {:.2f}'.format(recall))\n",
        "print('F1-Score: {:.2f}'.format(f1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'review_es'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# load the trained joblib model\n",
        "model2 = joblib.load('assets/modelo.joblib')\n",
        "\n",
        "tweets_df2 = pd.read_csv('/Users/pipe/Downloads/PeliculasRevisiones/MovieReviewsPruebas.csv', sep = ',')\n",
        "print(tweets_df2.columns)\n",
        "data2 = tweets_df2['review_es']\n",
        "\n",
        "# make predictions on the test dataset\n",
        "pred = model2.predict(data2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "message = \"Creo que hace dos años desde que he visto la película y hasta el día de hoy, es la peor película que he visto.Lo único que pensé después de ver esta película fue que fue hecha para algún motivo fiscal.Así que después de todo este tiempo, finalmente derramé mi intestino;) Y ahora IMDB dice que tengo que llenar 10 líneas con comentarios: Lo sentimos, debe proporcionar al menos 10 líneas en su comentario. Por favor regrese a la ventana Editar (o use la parte posteriorOpción Si esta no es una ventana nueva). Por favor, no hay nada que decir más ... Lo siento por un mal inglés.\"\n",
        "\n",
        "message = [message]\n",
        "\n",
        "result = model2.predict(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "i66s_iKNErEt",
        "iUjq05ziJ6P5",
        "hO4mNm_fG_7X",
        "wRqtq1zNPJpr",
        "tB75LnU3PNu2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
